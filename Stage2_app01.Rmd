---
title: 'Appendix 1: Sensitivity analysis of match advantage'
#tags: `PSA002`
output: pdf_document
header-includes:
  - \usepackage{caption}
  - \usepackage{float}
  - \captionsetup[table]{name=Table S,labelsep = period}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
library(data.table)
library(flextable)
library(lme4)
library(lmerTest)
library(parameters)
```

```{r init, message=FALSE, warning=FALSE}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

The R codes for the sensitivity analysis on the trial level were written by Erin M. Buchanan. Source codes are accessible at the project OSF ( https://osf.io/p7avr/ ).

## Load data and run models

The data for the sensitivity analysis shared the same exclusion criterion for the preregistered mixed-effect models. See the comments in the below codes.

```{r Trial-count, echo=TRUE}
## load lme data
SP_V_lme_data <-  dir(path = "includes/files/",
      pattern = "SP_V_lme_data.csv",
            recursive = TRUE, full.names = TRUE) %>% 
      read_csv()

number_trials <- SP_V_lme_data %>%
   filter(Outlier == FALSE) %>%  ## excluded outliers by MAD
  filter(Acc_bound == FALSE) %>% # remove people who were less than 70% so they don't match with join
  group_by(Subject, Match) %>%
  summarize(count = n())
```


```{r model, echo=TRUE}
models <- list()

for (i in 4:8){

  subjects <- number_trials %>%
       filter(count >= i) %>%
       pull(Subject) %>% unique()

  temp_data <- SP_V_lme_data %>%
       filter(Subject %in% subjects)

#only intercept
models[[paste("intercept.model", i, sep = "_")]] <- lm(response_time ~ 1, 
                      data = temp_data)

#add random intercept of subject
models[[paste("subject.model", i, sep = "_")]] <- lmer(response_time ~ 1 + (1|Subject), 
                      control = lmerControl(optimizer = "bobyqa",
                                            optCtrl = list(maxfun = 1e6)), 
                      data = temp_data)

# add random intercept of item
models[[paste("item.model", i, sep = "_")]] <- lmer(response_time ~ 1 + (1|Subject) + (1|Target), 
                      control = lmerControl(optimizer = "bobyqa",
                                            optCtrl = list(maxfun = 1e6)), 
                      data = temp_data)

# add random intercept of lab
models[[paste("lab.model", i, sep = "_")]]  <- lmer(response_time ~ 1 + (1|Subject) + (1|Target) + (1|PSA_ID), 
                      control = lmerControl(optimizer = "bobyqa",
                                            optCtrl = list(maxfun = 1e6)), 
                      data = temp_data)

# add random intercept of language
models[[paste("language.model", i, sep = "_")]] <- lmer(response_time ~ 1 + (1|Subject) + (1|Target) + (1|PSA_ID) + (1|Language), 
                      control = lmerControl(optimizer = "bobyqa",
                                            optCtrl = list(maxfun = 1e6)), 
                      data = temp_data)


# add fixed effect of match
models[[paste("fixed.four.model", i, sep = "_")]] <- lmer(response_time ~ Match + (1|Subject) + (1|Target) + (1|PSA_ID) + (1|Language),
control = lmerControl(optimizer = "bobyqa",
optCtrl = list(maxfun = 1e6)),
data = temp_data)
}
```

## View the Results


```{r AIC-computation, echo=TRUE}
AIC_values <- as.data.frame(unlist(lapply(models, AIC))) %>%
rename("AIC" = "unlist(lapply(models, AIC))")
AIC_values$model <- rownames(AIC_values)
AIC_values <- tidyr::separate(AIC_values,
                              model,
into = c("model", "number_trials"), sep = "_") %>%
pivot_wider(data = .,
     id_cols = c(number_trials),
     values_from = AIC,
     names_from = model)

AIC_values %>% knitr::kable()
```

When participants contributed to at least 8 trials, each mixed-effect model has the smallest AICs. Each model was lower than the previous models 2 AIC. The estimated fixed effect of matching condition was `r round(fixef(models$fixed.four.model_8)["MatchY"],2)`.